# URP渲染流程前言
无论是在默认URP的基础上修改渲染流程 还是自定义一套渲染方案
都需要对URP的渲染流程有足够的了解 而URP的渲染流程基于一些简单的接口

URP只是SRP的一种自定义扩展 他还有一个大哥叫HDRP
只需继承SRP的接口并实现特定的功能就能定义一个自己的渲染流程
当然 最好是在URP或者HDRP的基础上修改来实现自己的目标 容易实现
新人最好直接看源代码 解决部分疑惑再看这种总结性的文章

# RenderPipelineAsset
这是一个可序列化的资源 赋值在Graphics设置或Quality设置
为什么有两个地方可以设置是因为Quality设置有多个档次 Graphics设置的是默认值
设置好了RenderPipelineAsset后Unity就判断用户使用了SRP 而不是Built in管线

我们来看RenderPipelineAsset的继承者需要实现哪些功能：
renderingLayerMaskNames：新的RenderLayer功能中需要提供自定义Layer名
prefixedRenderingLayerMaskNames：对RenderLayer的描述名
有一大堆的材质球和Shader：这个就好比Built in管线中的Lit材质与Shader
CreatePipeline：创建管线实例

总结RenderPipelineAsset：
1.一般来说我们只需要一个管线实例 所以管线实例是个单例
2.RenderPipelineAsset的要继承的参数都是用于补全一些编辑器默认行为的
比如当用户导入一个模型就需要创建默认的材质球用于预览 也就是材质导入工作流
3.URP的RenderPipelineAsset挂了非常多的自定义字段 这些字段都是一些渲染设置
这些字段可以放在别的文件里 不一定非要挤在一起

# RenderPipeline
RenderPipeline的继承：
defaultSettings：新的RenderPipelineGlobalSettings 可以自定义全局配置
Render：渲染入口 渲染一帧
有一大堆的委托方法：用于在渲染的各个阶段插入事件 比如在渲染前初始化水系统

总结RenderPipeline：
1.作为单例RenderPipeline贯穿了整个app的生命周期
2.Render方法渲染一帧图像并提交到backBuffer
3.事件委托用的人少 咱们知道如何添加委托会在哪里调用就行 相对鸡肋
4.最精简的管线 比如遍历相机并渲染一个Quad到CameraTarget
将最终渲染结果Blit到CarmeraTarget的行为我们称作FinalBlit
5.RenderPipeline只处理最外层的渲染任务安排 不与渲染品质相关
6.URP同时作为生产和工作环境 需要处理好多种相机的渲染 如：
Game相机 用于输出最终游戏内容 可以多相机叠加 支持模拟手机
在Scene视图下选中Game相机看到的Game相机预览
Scene视图相机 支持多种debug渲染模式
Preview相机 用于渲染材质预览、模型预览

Render方法主要流程：
1.设置管线固定配置：如果会运行时变化就逐帧 如果不变就在实例化时赋值一次
QualitySettings.antiAliasing：MSAA我打算不用 除非是做成了渲染配置才需要变
GraphicsSettings.lightsUseLinearIntensity：HDR的颜色不做Gamma矫正
是否支持HDR：用不用是另一个问题 主要是判断RT支持和平台
颜色空间：必须是Linear的
2.声明逐帧的全局变量：这些变量与具体的相机和物件没有关联 可以先声明
3.排序和整理相机 遍历相机执行渲染

RenderCameraStack方法主要流程：
URP在处理多相机渲染流程时提出了一个栈的概念
首先渲染Base相机 后续的Overlay相机在Base的输出结果上继续渲染
我们需要在Base和Overlay的基础上去执行抗锯齿、后处理、减少OverDraw
如果Overlay相机完全覆盖了Base相机 那么Base相机就是在做无效输出了
比如原神的阵容界面打开时是全屏的 这样的完全遮挡关系比半遮挡关系简单
回到RenderCameraStack方法
如果Base相机后没有Overlay相机 那么Base相机执行FinalBlit
有很多特殊的相机没有挂载AdditionalCameraData组件或者相机类型不是Game：
反射探针：每次更新时使用6个相机渲染6个面构成Cubemap
SceneView、SceneView预览、Preview等相机
特殊相机就当做Base类型且使用默认的渲染设置即可
栈的情况比较复杂 比如相机之间的衔接工作 这里只是大概讲一讲

Volmume系统：
现在我们创建后处理配置的时候都是创建VolumeProfile文件
主要就是想实现在大的场景里构成Volume网络
人物行走在网络中时对Volume上的后处理参数进行差值
这样就能实现动态的后处理变化 也许会带来惊人的效果

在渲染单个相机任务之前收集帧数据 RenderingData：
RenderingData包含的东西很多 看不过来可以等解决具体问题的时候再看
在执行RenderSingleCamera方法之前需要准备好cameraData
而因为栈的原因 Overlay相机的cameraData会继承部分Base相机的属性
进入RenderSingleCamera方法后：
1.TryGetCullingParameters ：获取剔除参数 为CPU端粗粒度剔除做准备
2.renderer.Clear ：重置颜色和深度RT
m_CameraColorTarget ：关键的颜色目标 所有尝试都是为了在这里写入颜色
m_ActiveColorAttachments ：临时的渲染目标 根据渲染步骤频繁切换的颜色目标
3.renderer.OnPreCullRenderPasses ：一个接口 用于在Cull前触发FeaturePass的逻辑
    现在唯一调用了这个接口的行为来自于DecalSkipCulledSystem
4.renderer.SetupCullingParameters ：在Cull前对剔除参数的修改
    裁剪结果是否包含阴影物体
    最大可见光源数量
    阴影物体剔除时 光源空间的视椎体长度
5.ScriptableRenderContext.EmitWorldGeometryForSceneView ：生成UGUI物体的mesh
6.context.Cull ：执行CPU端的相机粗粒度剔除 得到cullResults
    决定哪些物体、光源是可见的
7.InitializeRenderingData ：基于剔除结果和cameraData收集更多数据
    InitializeLightData 收集光源数据
    InitializeShadowData 收集阴影数据
    InitializePostProcessingData 收集后处理数据
8.renderer.AddRenderPasses ：从序列化的pass列表中添加合适的pass到待执行列表
9.renderer.Setup ：初始化一些URP内置的Pass
    我倾向于将内置Pass和自定义的FeaturePass可视化处理 减少代码的复杂度
10.renderer.Execute ：在pass列表已经确定的情况下执行列表
    SetupRenderPasses ：逐pass初始化 可将关键的颜色目标设置为全局RT
    InternalStartRendering ：创角RT和配置特殊的RenderTarget 表现当前Pass的意图
    ClearRenderingState ：清楚一些全局关键字 这些关键字都是逐相机判断的
    SetShaderTimeValues ：设置时间参数
    SortStable ：pass列表根据优先级排序 pass的插队需使用指定优先级插入到某个阶段
    SetupNativeRenderPassFrameData ： NativeRenderPass功能 可开启framebuffer fetch
    SetupLights : 设置光源全局属性 可选的Clustered多光源光照算法
    ExecuteBlock ：将渲染分成渲染前 | 不透明 | 透明 | 后处理等Block 分块执行
    DrawGizmos ：渲染光源、相机等SceneView参考物体
    InternalFinishRendering ：处理相机渲染结束事件 清理pass列表
